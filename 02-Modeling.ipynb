{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ef796ae-ec1a-4407-ad79-b952fd22d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries and packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67ff121f-f8d4-415a-8b18-dd7633518615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load Data ---\n",
    "DB_PATH = 'data/cta_database.db'\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "query = \"SELECT * FROM train_positions\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3154a15d-79a6-4255-8241-839b9b94c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-create the datetime features from EDA\n",
    "df['fetch_datetime'] = pd.to_datetime(df['fetch_timestamp'], unit='s')\n",
    "df['hour_of_day'] = df['fetch_datetime'].dt.hour\n",
    "df['day_of_week'] = df['fetch_datetime'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "517eb73f-deca-4c88-b2f7-89633247bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Define Target Variable and Features ---\n",
    "# For this first model, let's predict speed.\n",
    "# We'll drop rows with missing data for simplicity.\n",
    "df.dropna(subset=['latitude', 'longitude', 'heading'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73449c78-f8c7-4d04-b8f3-17582a3a03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'speed_kmh' # We need to calculate this feature first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a256219a-f3d4-445a-b2fa-f3ca6ecb1df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll calculate speed just like in the EDA notebook\n",
    "# (This ensures our modeling notebook is self-contained)\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(delta_phi / 2.0)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2.0)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38f5470e-0046-4873-85d1-b542be797d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by=['run_number', 'fetch_timestamp']).copy()\n",
    "df_sorted['time_diff_s'] = df_sorted.groupby('run_number')['fetch_timestamp'].diff()\n",
    "df_sorted['lat_prev'] = df_sorted.groupby('run_number')['latitude'].shift(1)\n",
    "df_sorted['lon_prev'] = df_sorted.groupby('run_number')['longitude'].shift(1)\n",
    "df_sorted['distance_m'] = haversine_distance(df_sorted['lat_prev'], df_sorted['lon_prev'], df_sorted['latitude'], df_sorted['longitude'])\n",
    "df_sorted['speed_mps'] = (df_sorted['distance_m'] / df_sorted['time_diff_s']).fillna(0)\n",
    "df_sorted['speed_kmh'] = df_sorted['speed_mps'] * 3.6\n",
    "df = df_sorted.dropna(subset=[TARGET]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce8cd8eb-cc99-4e02-9a0a-0f22b93e7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns are features (X) and which is the target (y)\n",
    "features = ['latitude', 'longitude', 'heading', 'hour_of_day', 'day_of_week', 'is_delayed', 'next_station_name']\n",
    "X = df[features]\n",
    "y = df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f27f13f7-3641-4a1a-aa9b-87160c695a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 23167\n",
      "Validation set size: 7723\n",
      "Test set size: 7723\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Time-Based Data Split ---\n",
    "# It's crucial to split time-series data chronologically\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "512dfa81-4fcf-47ef-b7b6-5c92393258c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Preprocessing Pipeline Setup ---\n",
    "# Define which columns need which transformation\n",
    "numerical_features = ['latitude', 'longitude', 'heading', 'hour_of_day']\n",
    "categorical_features = ['day_of_week', 'next_station_name', 'is_delayed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65fa67fe-70b4-4651-b61c-59090be175f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the preprocessing pipelines for numerical and categorical data\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5e43c58-26de-423c-9e65-1776dd67c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough' # Keep other columns (if any)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba71fdd5-6178-4690-8e56-eac3ad71a307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>heading</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_delayed</th>\n",
       "      <th>next_station_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34697</th>\n",
       "      <td>41.78054</td>\n",
       "      <td>-87.631</td>\n",
       "      <td>358</td>\n",
       "      <td>3</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>Garfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34716</th>\n",
       "      <td>41.78054</td>\n",
       "      <td>-87.631</td>\n",
       "      <td>358</td>\n",
       "      <td>3</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>Garfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34735</th>\n",
       "      <td>41.78054</td>\n",
       "      <td>-87.631</td>\n",
       "      <td>358</td>\n",
       "      <td>3</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>Garfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34753</th>\n",
       "      <td>41.78054</td>\n",
       "      <td>-87.631</td>\n",
       "      <td>358</td>\n",
       "      <td>3</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>Garfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34770</th>\n",
       "      <td>41.78054</td>\n",
       "      <td>-87.631</td>\n",
       "      <td>358</td>\n",
       "      <td>3</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>Garfield</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude  longitude  heading  hour_of_day day_of_week  is_delayed  \\\n",
       "34697  41.78054    -87.631      358            3    Saturday           0   \n",
       "34716  41.78054    -87.631      358            3    Saturday           0   \n",
       "34735  41.78054    -87.631      358            3    Saturday           0   \n",
       "34753  41.78054    -87.631      358            3    Saturday           1   \n",
       "34770  41.78054    -87.631      358            3    Saturday           1   \n",
       "\n",
       "      next_station_name  \n",
       "34697          Garfield  \n",
       "34716          Garfield  \n",
       "34735          Garfield  \n",
       "34753          Garfield  \n",
       "34770          Garfield  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first few rows of the training data\n",
    "display(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f595fcf-d161-4d4b-bfb8-e38e912c79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Create and Train the LightGBM Model ---\n",
    "\n",
    "# Create a full pipeline that includes the preprocessor and the model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', lgb.LGBMRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa22e01e-9679-4471-a86e-fb9ff10fd41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the LightGBM model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 593\n",
      "[LightGBM] [Info] Number of data points in the train set: 23167, number of used features: 43\n",
      "[LightGBM] [Info] Start training from score 30.434718\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Train the entire pipeline on the training data\n",
    "print(\"Training the LightGBM model...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e09e48fe-1108-4e95-b7d9-166b752b84ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/transit_anomaly/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Evaluate the Model ---\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_val = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "108df138-0193-4124-913a-6b67d714e326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Performance on Validation Set ---\n",
      "Mean Absolute Error (MAE): 12.88 km/h\n",
      "R-squared (R²): 0.41\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(y_val, y_pred_val)\n",
    "r2 = r2_score(y_val, y_pred_val)\n",
    "print(f\"\\n--- Model Performance on Validation Set ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f} km/h\")\n",
    "print(f\"R-squared (R²): {r2:.2f}\")\n",
    "print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e4c4dcc-969d-40ed-a1bf-dc7442c68b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Speed</th>\n",
       "      <th>Predicted Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3911</th>\n",
       "      <td>28.547153</td>\n",
       "      <td>23.798657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>20.215736</td>\n",
       "      <td>20.965544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>25.140537</td>\n",
       "      <td>19.747951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>17.986848</td>\n",
       "      <td>20.694850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>18.288609</td>\n",
       "      <td>18.538144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>42.749704</td>\n",
       "      <td>22.266537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>16.685226</td>\n",
       "      <td>24.534818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>16.344857</td>\n",
       "      <td>22.266537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>31.538146</td>\n",
       "      <td>29.061327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4096</th>\n",
       "      <td>12.113310</td>\n",
       "      <td>16.985500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Speed  Predicted Speed\n",
       "3911     28.547153        23.798657\n",
       "3932     20.215736        20.965544\n",
       "3953     25.140537        19.747951\n",
       "3974     17.986848        20.694850\n",
       "3995     18.288609        18.538144\n",
       "4015     42.749704        22.266537\n",
       "4036     16.685226        24.534818\n",
       "4056     16.344857        22.266537\n",
       "4076     31.538146        29.061327\n",
       "4096     12.113310        16.985500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a few sample predictions vs actual values\n",
    "results_df = pd.DataFrame({'Actual Speed': y_val, 'Predicted Speed': y_pred_val})\n",
    "print(\"\\nSample Predictions:\")\n",
    "display(results_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b0204-49a1-42f9-8f6b-b1951a6ef272",
   "metadata": {},
   "source": [
    "### MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25e2a049-1807-4c4e-9d2a-857ed6b6d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b4cfb78-86dd-4049-b18d-95d2ce94df06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/gauravkhanal/Documents/transit_anomaly/mlruns/967605301230387316', creation_time=1756408536360, experiment_id='967605301230387316', last_update_time=1756408536360, lifecycle_stage='active', name='CTA Train Speed Prediction', tags={}>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 7. Log Experiment with MLflow ---\n",
    "\n",
    "# Set the experiment name. MLflow will create it if it doesn't exist.\n",
    "mlflow.set_experiment(\"CTA Train Speed Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c30aeff9-c582-4a7b-a822-df82ff1991e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MLflow run...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 593\n",
      "[LightGBM] [Info] Number of data points in the train set: 23167, number of used features: 43\n",
      "[LightGBM] [Info] Start training from score 30.434718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/transit_anomaly/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025/08/30 15:22:44 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "/opt/anaconda3/envs/transit_anomaly/lib/python3.10/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/transit_anomaly/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logging metrics ---\n",
      "MAE: 12.88\n",
      "R2: 0.41\n",
      "\n",
      "MLflow run complete. Model, metrics, and signature have been logged.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/transit_anomaly/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Start an MLflow run. Everything inside this block will be logged.\n",
    "with mlflow.start_run(run_name=\"LightGBM_Baseline\"):\n",
    "    print(\"Starting MLflow run...\")\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred_val = pipeline.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, y_pred_val)\n",
    "    r2 = r2_score(y_val, y_pred_val)\n",
    "\n",
    "    print(f\"\\n--- Logging metrics ---\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"R2: {r2:.2f}\")\n",
    "\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # --- FIX: Add the input_example parameter ---\n",
    "    # This will automatically create and save the model's signature.\n",
    "    mlflow.sklearn.log_model(\n",
    "        pipeline,\n",
    "        \"lightgbm_model\",\n",
    "        input_example=X_train.head(1) # Use one row of training data as an example\n",
    "    )\n",
    "\n",
    "    print(\"\\nMLflow run complete. Model, metrics, and signature have been logged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb30946-5831-4b23-a8c9-8116cba5efc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (transit_anomaly)",
   "language": "python",
   "name": "transit_anomaly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
