{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ef796ae-ec1a-4407-ad79-b952fd22d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries and packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67ff121f-f8d4-415a-8b18-dd7633518615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load Data ---\n",
    "DB_PATH = 'data/cta_database.db'\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "query = \"SELECT * FROM train_positions\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3154a15d-79a6-4255-8241-839b9b94c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-create the datetime features from EDA\n",
    "df['fetch_datetime'] = pd.to_datetime(df['fetch_timestamp'], unit='s')\n",
    "df['hour_of_day'] = df['fetch_datetime'].dt.hour\n",
    "df['day_of_week'] = df['fetch_datetime'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "517eb73f-deca-4c88-b2f7-89633247bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Define Target Variable and Features ---\n",
    "# For this first model, let's predict speed.\n",
    "# We'll drop rows with missing data for simplicity.\n",
    "df.dropna(subset=['latitude', 'longitude', 'heading'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73449c78-f8c7-4d04-b8f3-17582a3a03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'speed_kmh' # We need to calculate this feature first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a256219a-f3d4-445a-b2fa-f3ca6ecb1df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll calculate speed just like in the EDA notebook\n",
    "# (This ensures our modeling notebook is self-contained)\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(delta_phi / 2.0)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2.0)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38f5470e-0046-4873-85d1-b542be797d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by=['run_number', 'fetch_timestamp']).copy()\n",
    "df_sorted['time_diff_s'] = df_sorted.groupby('run_number')['fetch_timestamp'].diff()\n",
    "df_sorted['lat_prev'] = df_sorted.groupby('run_number')['latitude'].shift(1)\n",
    "df_sorted['lon_prev'] = df_sorted.groupby('run_number')['longitude'].shift(1)\n",
    "df_sorted['distance_m'] = haversine_distance(df_sorted['lat_prev'], df_sorted['lon_prev'], df_sorted['latitude'], df_sorted['longitude'])\n",
    "df_sorted['speed_mps'] = (df_sorted['distance_m'] / df_sorted['time_diff_s']).fillna(0)\n",
    "df_sorted['speed_kmh'] = df_sorted['speed_mps'] * 3.6\n",
    "df = df_sorted.dropna(subset=[TARGET]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce8cd8eb-cc99-4e02-9a0a-0f22b93e7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns are features (X) and which is the target (y)\n",
    "features = ['latitude', 'longitude', 'heading', 'hour_of_day', 'day_of_week', 'is_delayed', 'next_station_name']\n",
    "X = df[features]\n",
    "y = df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f27f13f7-3641-4a1a-aa9b-87160c695a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 12171\n",
      "Validation set size: 4057\n",
      "Test set size: 4058\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Time-Based Data Split ---\n",
    "# It's crucial to split time-series data chronologically\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "512dfa81-4fcf-47ef-b7b6-5c92393258c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Preprocessing Pipeline Setup ---\n",
    "# Define which columns need which transformation\n",
    "numerical_features = ['latitude', 'longitude', 'heading', 'hour_of_day']\n",
    "categorical_features = ['day_of_week', 'next_station_name', 'is_delayed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65fa67fe-70b4-4651-b61c-59090be175f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the preprocessing pipelines for numerical and categorical data\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5e43c58-26de-423c-9e65-1776dd67c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough' # Keep other columns (if any)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba71fdd5-6178-4690-8e56-eac3ad71a307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>heading</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_delayed</th>\n",
       "      <th>next_station_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>42.01906</td>\n",
       "      <td>-87.67289</td>\n",
       "      <td>130</td>\n",
       "      <td>16</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>Morse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4832</th>\n",
       "      <td>42.00836</td>\n",
       "      <td>-87.66591</td>\n",
       "      <td>178</td>\n",
       "      <td>16</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>Loyola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19486</th>\n",
       "      <td>41.72238</td>\n",
       "      <td>-87.62441</td>\n",
       "      <td>358</td>\n",
       "      <td>18</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0</td>\n",
       "      <td>87th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19508</th>\n",
       "      <td>41.73537</td>\n",
       "      <td>-87.62475</td>\n",
       "      <td>357</td>\n",
       "      <td>18</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0</td>\n",
       "      <td>79th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19530</th>\n",
       "      <td>41.74091</td>\n",
       "      <td>-87.62488</td>\n",
       "      <td>357</td>\n",
       "      <td>18</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0</td>\n",
       "      <td>79th</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude  longitude  heading  hour_of_day day_of_week  is_delayed  \\\n",
       "4811   42.01906  -87.67289      130           16   Wednesday           0   \n",
       "4832   42.00836  -87.66591      178           16   Wednesday           0   \n",
       "19486  41.72238  -87.62441      358           18    Thursday           0   \n",
       "19508  41.73537  -87.62475      357           18    Thursday           0   \n",
       "19530  41.74091  -87.62488      357           18    Thursday           0   \n",
       "\n",
       "      next_station_name  \n",
       "4811              Morse  \n",
       "4832             Loyola  \n",
       "19486              87th  \n",
       "19508              79th  \n",
       "19530              79th  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first few rows of the training data\n",
    "display(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f595fcf-d161-4d4b-bfb8-e38e912c79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Create and Train the LightGBM Model ---\n",
    "\n",
    "# Create a full pipeline that includes the preprocessor and the model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', lgb.LGBMRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa22e01e-9679-4471-a86e-fb9ff10fd41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the LightGBM model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 12171, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 31.624262\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Train the entire pipeline on the training data\n",
    "print(\"Training the LightGBM model...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e09e48fe-1108-4e95-b7d9-166b752b84ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/transit_anomaly/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Evaluate the Model ---\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_val = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "108df138-0193-4124-913a-6b67d714e326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Performance on Validation Set ---\n",
      "Mean Absolute Error (MAE): 12.71 km/h\n",
      "R-squared (R²): 0.43\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(y_val, y_pred_val)\n",
    "r2 = r2_score(y_val, y_pred_val)\n",
    "print(f\"\\n--- Model Performance on Validation Set ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f} km/h\")\n",
    "print(f\"R-squared (R²): {r2:.2f}\")\n",
    "print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e4c4dcc-969d-40ed-a1bf-dc7442c68b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Speed</th>\n",
       "      <th>Predicted Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>22.319575</td>\n",
       "      <td>15.521432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>44.376751</td>\n",
       "      <td>32.645638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.645638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4518</th>\n",
       "      <td>36.233518</td>\n",
       "      <td>20.301292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4537</th>\n",
       "      <td>29.735171</td>\n",
       "      <td>23.044429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4555</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.563419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>28.755693</td>\n",
       "      <td>22.059349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4592</th>\n",
       "      <td>32.258811</td>\n",
       "      <td>18.120851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.120851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <td>71.285010</td>\n",
       "      <td>26.430163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Speed  Predicted Speed\n",
       "4463     22.319575        15.521432\n",
       "4482     44.376751        32.645638\n",
       "4500      0.000000        32.645638\n",
       "4518     36.233518        20.301292\n",
       "4537     29.735171        23.044429\n",
       "4555      0.000000        22.563419\n",
       "4573     28.755693        22.059349\n",
       "4592     32.258811        18.120851\n",
       "4611      0.000000        18.120851\n",
       "4630     71.285010        26.430163"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a few sample predictions vs actual values\n",
    "results_df = pd.DataFrame({'Actual Speed': y_val, 'Predicted Speed': y_pred_val})\n",
    "print(\"\\nSample Predictions:\")\n",
    "display(results_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b0204-49a1-42f9-8f6b-b1951a6ef272",
   "metadata": {},
   "source": [
    "### MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25e2a049-1807-4c4e-9d2a-857ed6b6d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b4cfb78-86dd-4049-b18d-95d2ce94df06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/gauravkhanal/Documents/transit_anomaly/mlruns/967605301230387316', creation_time=1756408536360, experiment_id='967605301230387316', last_update_time=1756408536360, lifecycle_stage='active', name='CTA Train Speed Prediction', tags={}>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 7. Log Experiment with MLflow ---\n",
    "\n",
    "# Set the experiment name. MLflow will create it if it doesn't exist.\n",
    "mlflow.set_experiment(\"CTA Train Speed Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c30aeff9-c582-4a7b-a822-df82ff1991e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MLflow run...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 12171, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 31.624262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/transit_anomaly/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025/08/28 22:37:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "/opt/anaconda3/envs/transit_anomaly/lib/python3.10/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/transit_anomaly/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logging metrics ---\n",
      "MAE: 12.71\n",
      "R2: 0.43\n",
      "\n",
      "MLflow run complete. Model, metrics, and signature have been logged.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/transit_anomaly/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Start an MLflow run. Everything inside this block will be logged.\n",
    "with mlflow.start_run(run_name=\"LightGBM_Baseline\"):\n",
    "    print(\"Starting MLflow run...\")\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred_val = pipeline.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, y_pred_val)\n",
    "    r2 = r2_score(y_val, y_pred_val)\n",
    "\n",
    "    print(f\"\\n--- Logging metrics ---\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"R2: {r2:.2f}\")\n",
    "\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # --- FIX: Add the input_example parameter ---\n",
    "    # This will automatically create and save the model's signature.\n",
    "    mlflow.sklearn.log_model(\n",
    "        pipeline,\n",
    "        \"lightgbm_model\",\n",
    "        input_example=X_train.head(1) # Use one row of training data as an example\n",
    "    )\n",
    "\n",
    "    print(\"\\nMLflow run complete. Model, metrics, and signature have been logged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdb30946-5831-4b23-a8c9-8116cba5efc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3574192917.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    mlflow ui\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mlflow ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (transit_anomaly)",
   "language": "python",
   "name": "transit_anomaly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
