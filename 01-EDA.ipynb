{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c099243c-d639-4433-b770-af3bcfccc46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries and packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from scipy import stats\n",
    "from math import radians, cos, sin, asin, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b1abdc4-1d12-443e-857b-dad16374eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib for better plots\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",\n",
    "    \"figure.figsize\": (12, 8),\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.alpha\": 0.3\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae78677b-86ea-4647-b31d-568903aa5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some display options for pandas\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba710293-c0cc-4262-8855-8e4d43acfe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the database\n",
    "DB_PATH = \"data/cta_database.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567448e0-cb5d-4c5f-89d2-390295e9c712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect(DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6cba070-6fd7-48e6-88b6-b52812cae44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL query to select all data from the table\n",
    "query = \"SELECT * FROM train_positions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dd1ac97-413e-45ae-b3c0-14fd9853aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a Pandas DataFrame\n",
    "df = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51b96294-3a35-491e-8f4f-3889501983ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-overview",
   "metadata": {},
   "source": [
    "## Data Overview & Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initial Inspection ---\n",
    "print(f\"Shape of the dataset: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "print(\"\\nData Info:\")\n",
    "df.info()\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Date range: {pd.to_datetime(df['fetch_timestamp'], unit='s').min()} to {pd.to_datetime(df['fetch_timestamp'], unit='s').max()}\")\n",
    "print(f\"Unique routes: {df['route_name'].nunique()}\")\n",
    "print(f\"Unique trains: {df['run_number'].nunique()}\")\n",
    "print(f\"Records with delays: {df['is_delayed'].sum():,} ({df['is_delayed'].mean():.1%})\")\n",
    "\n",
    "# Route distribution\n",
    "print(\"\\nRecords by route:\")\n",
    "print(df['route_name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-engineering",
   "metadata": {},
   "source": [
    "## Feature Engineering for Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculate-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate the great circle distance between two points on earth (in km)\"\"\"\n",
    "    # Convert decimal degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371  # Radius of earth in kilometers\n",
    "    return c * r\n",
    "\n",
    "# Sort by train and timestamp for speed calculation\n",
    "df_sorted = df.sort_values(['run_number', 'fetch_timestamp']).copy()\n",
    "\n",
    "# Calculate speed for each train\n",
    "df_sorted['prev_lat'] = df_sorted.groupby('run_number')['latitude'].shift(1)\n",
    "df_sorted['prev_lon'] = df_sorted.groupby('run_number')['longitude'].shift(1)\n",
    "df_sorted['prev_timestamp'] = df_sorted.groupby('run_number')['fetch_timestamp'].shift(1)\n",
    "\n",
    "# Calculate distance and time differences\n",
    "mask = df_sorted[['prev_lat', 'prev_lon', 'prev_timestamp']].notna().all(axis=1)\n",
    "df_sorted.loc[mask, 'distance_km'] = df_sorted.loc[mask].apply(\n",
    "    lambda row: haversine_distance(row['prev_lat'], row['prev_lon'], row['latitude'], row['longitude']), \n",
    "    axis=1\n",
    ")\n",
    "df_sorted.loc[mask, 'time_diff_hours'] = (df_sorted.loc[mask, 'fetch_timestamp'] - df_sorted.loc[mask, 'prev_timestamp']) / 3600\n",
    "\n",
    "# Calculate speed (km/h), handle division by zero\n",
    "df_sorted.loc[mask, 'speed_kmh'] = df_sorted.loc[mask, 'distance_km'] / df_sorted.loc[mask, 'time_diff_hours']\n",
    "df_sorted.loc[df_sorted['time_diff_hours'] == 0, 'speed_kmh'] = 0\n",
    "\n",
    "# Add time-based features\n",
    "df_sorted['datetime'] = pd.to_datetime(df_sorted['fetch_timestamp'], unit='s')\n",
    "df_sorted['hour_of_day'] = df_sorted['datetime'].dt.hour\n",
    "df_sorted['day_of_week'] = df_sorted['datetime'].dt.dayofweek\n",
    "df_sorted['is_weekend'] = df_sorted['day_of_week'].isin([5, 6])\n",
    "df_sorted['is_rush_hour'] = df_sorted['hour_of_day'].isin([7, 8, 9, 17, 18, 19])\n",
    "\n",
    "print(f\"Speed calculation complete. Records with speed data: {df_sorted['speed_kmh'].notna().sum():,}\")\n",
    "print(f\"Speed statistics (km/h):\")\n",
    "print(df_sorted['speed_kmh'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-analysis",
   "metadata": {},
   "source": [
    "## Temporal Patterns Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for temporal analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Speed by hour of day\n",
    "hourly_speed = df_sorted.groupby('hour_of_day')['speed_kmh'].agg(['mean', 'std']).reset_index()\n",
    "axes[0,0].plot(hourly_speed['hour_of_day'], hourly_speed['mean'], marker='o')\n",
    "axes[0,0].fill_between(hourly_speed['hour_of_day'], \n",
    "                       hourly_speed['mean'] - hourly_speed['std'],\n",
    "                       hourly_speed['mean'] + hourly_speed['std'], alpha=0.3)\n",
    "axes[0,0].set_title('Average Speed by Hour of Day')\n",
    "axes[0,0].set_xlabel('Hour')\n",
    "axes[0,0].set_ylabel('Speed (km/h)')\n",
    "\n",
    "# Delay rate by hour\n",
    "hourly_delays = df_sorted.groupby('hour_of_day')['is_delayed'].mean()\n",
    "axes[0,1].bar(hourly_delays.index, hourly_delays.values)\n",
    "axes[0,1].set_title('Delay Rate by Hour of Day')\n",
    "axes[0,1].set_xlabel('Hour')\n",
    "axes[0,1].set_ylabel('Delay Rate')\n",
    "\n",
    "# Speed distribution by route\n",
    "route_speeds = [df_sorted[df_sorted['route_name'] == route]['speed_kmh'].dropna() \n",
    "                for route in df_sorted['route_name'].unique()]\n",
    "axes[1,0].boxplot(route_speeds, labels=df_sorted['route_name'].unique())\n",
    "axes[1,0].set_title('Speed Distribution by Route')\n",
    "axes[1,0].set_xlabel('Route')\n",
    "axes[1,0].set_ylabel('Speed (km/h)')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Rush hour vs non-rush hour speeds\n",
    "rush_speeds = df_sorted[df_sorted['is_rush_hour']]['speed_kmh'].dropna()\n",
    "non_rush_speeds = df_sorted[~df_sorted['is_rush_hour']]['speed_kmh'].dropna()\n",
    "axes[1,1].hist([rush_speeds, non_rush_speeds], bins=30, alpha=0.7, \n",
    "               label=['Rush Hour', 'Non-Rush Hour'])\n",
    "axes[1,1].set_title('Speed Distribution: Rush vs Non-Rush Hours')\n",
    "axes[1,1].set_xlabel('Speed (km/h)')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline-anomaly",
   "metadata": {},
   "source": [
    "## Baseline Anomaly Detection (Z-Score Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zscore-anomalies",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context-aware Z-score anomaly detection\n",
    "def detect_speed_anomalies(group, threshold=2.5):\n",
    "    \"\"\"Detect anomalies within a group using Z-score\"\"\"\n",
    "    if len(group) < 3:  # Need minimum samples\n",
    "        return pd.Series([False] * len(group), index=group.index)\n",
    "    \n",
    "    z_scores = np.abs(stats.zscore(group['speed_kmh'].fillna(group['speed_kmh'].median())))\n",
    "    return z_scores > threshold\n",
    "\n",
    "# Apply anomaly detection grouped by route and hour\n",
    "df_sorted['is_speed_anomaly'] = df_sorted.groupby(['route_name', 'hour_of_day']).apply(\n",
    "    detect_speed_anomalies\n",
    ").reset_index(level=[0,1], drop=True)\n",
    "\n",
    "# Summary of anomalies\n",
    "anomaly_count = df_sorted['is_speed_anomaly'].sum()\n",
    "anomaly_rate = df_sorted['is_speed_anomaly'].mean()\n",
    "\n",
    "print(f\"Baseline Anomaly Detection Results:\")\n",
    "print(f\"Total anomalies detected: {anomaly_count:,}\")\n",
    "print(f\"Anomaly rate: {anomaly_rate:.2%}\")\n",
    "print(f\"\\nAnomalies by route:\")\n",
    "print(df_sorted.groupby('route_name')['is_speed_anomaly'].agg(['sum', 'mean']).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-analysis",
   "metadata": {},
   "source": [
    "## Spatial Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-geodataframe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create the GeoDataFrame from our train data ---\n",
    "# First, drop any rows that might have missing lat/lon data\n",
    "df_geo = df_sorted.dropna(subset=['latitude', 'longitude']).copy()\n",
    "\n",
    "# Create a 'geometry' column from the latitude and longitude\n",
    "# This is what makes the DataFrame \"map-aware\"\n",
    "geometry = [Point(xy) for xy in zip(df_geo['longitude'], df_geo['latitude'])]\n",
    "gdf_trains = gpd.GeoDataFrame(df_geo, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "# --- Load the Chicago map shapefile ---\n",
    "chicago_map = gpd.read_file(\"geo_data/Boundaries_-_City_20250823.geojson\")\n",
    "\n",
    "print(f\"GeoDataFrame created with {len(gdf_trains):,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create map visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Plot 1: All train positions colored by route\n",
    "chicago_map.plot(ax=axes[0], color='lightgray', alpha=0.5)\n",
    "for route in df_sorted['route_name'].unique():\n",
    "    route_data = df_sorted[df_sorted['route_name'] == route]\n",
    "    axes[0].scatter(route_data['longitude'], route_data['latitude'], \n",
    "                   label=route, alpha=0.6, s=1)\n",
    "axes[0].set_title('CTA Train Positions by Route')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel('Longitude')\n",
    "axes[0].set_ylabel('Latitude')\n",
    "\n",
    "# Plot 2: Anomalies highlighted\n",
    "chicago_map.plot(ax=axes[1], color='lightgray', alpha=0.5)\n",
    "normal_data = df_sorted[~df_sorted['is_speed_anomaly']]\n",
    "anomaly_data = df_sorted[df_sorted['is_speed_anomaly']]\n",
    "\n",
    "axes[1].scatter(normal_data['longitude'], normal_data['latitude'], \n",
    "               c='blue', alpha=0.3, s=1, label='Normal')\n",
    "axes[1].scatter(anomaly_data['longitude'], anomaly_data['latitude'], \n",
    "               c='red', alpha=0.8, s=10, label='Anomalies')\n",
    "axes[1].set_title('Speed Anomalies on Chicago Transit Map')\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('Longitude')\n",
    "axes[1].set_ylabel('Latitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some example anomalies\n",
    "print(\"\\nExample Speed Anomalies:\")\n",
    "anomaly_examples = df_sorted[df_sorted['is_speed_anomaly']].nlargest(5, 'speed_kmh')\n",
    "print(anomaly_examples[['datetime', 'route_name', 'run_number', 'speed_kmh', 'is_delayed']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions",
   "metadata": {},
   "source": [
    "## Key Findings & Next Steps\n",
    "\n",
    "### Observations:\n",
    "1. **Data Quality**: High-quality dataset with good coverage across all CTA lines\n",
    "2. **Temporal Patterns**: Clear rush hour effects and route-specific behaviors\n",
    "3. **Baseline Anomalies**: Z-score method identifies potential issues\n",
    "\n",
    "### For Advanced Modeling:\n",
    "1. **Feature Engineering**: Speed, time-based features, and spatial context\n",
    "2. **Sequence Data**: Train trajectories for LSTM modeling\n",
    "3. **Contextual Anomalies**: Route and time-specific baselines\n",
    "\n",
    "### Model Candidates:\n",
    "- **LightGBM**: For tabular anomaly detection\n",
    "- **LSTM**: For sequence-based anomalies\n",
    "- **Isolation Forest**: For unsupervised detection\n",
    "- **Conformal Prediction**: For statistical confidence bounds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}